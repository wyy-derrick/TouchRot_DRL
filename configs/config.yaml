# ==================== 项目配置文件 ====================
# LeapHand 灵巧手手内旋转任务 - SAC强化学习

# ==================== 环境配置 ====================
env:
  # 模型路径 (相对于项目根目录)
  model_path: "scene_left(cubic).xml"
  
  # 仿真参数
  frame_skip: 5                    # 每个RL步执行的物理步数
  max_episode_steps: 500          # 最大episode步数
  
  # 动作参数
  action_scale: 0.1                # 动作缩放因子
  
  # 触觉传感器参数
  tactile_threshold: 0.01          # 力阈值 (N)
  tactile_margin: 0.005            # 容忍距离 (m)
  
  # 终止条件
  drop_height: 0.05                # 掉落高度阈值 (m)

  # 指尖权重 (与 tip_site_names 顺序一致，默认: 食/中/无/拇 = 15%,15%,15%,55%)
  tip_site_weights: [0.15, 0.15, 0.15, 0.55]
  
  # 奖励权重
  reward_weights:
    rotation: 80.0                 # 强化旋转奖励，驱动主要目标
    velocity: -0.1                 # 抑制物体飞出
    torque: -0.0001                # 轻微力矩惩罚，抑制抖动
    work: -0.0001                  # 轻微功率惩罚
    drop: -100.0                    # 掉落惩罚
    distance: -0.0                 # 距离惩罚
    contact: 0.0                   # 不再单独奖励接触
    action: -0.0                 # 轻微动作惩罚
    fingertip_dist: 0.8           # 有界指尖距离奖励
    collision: -0.0001               # 非物体接触惩罚，抑制手指互撞/碰地

# ==================== SAC算法配置 ====================
sac:
  # 折扣因子
  gamma: 0.99
  
  # 软更新系数
  tau: 0.005
  
  # 学习率
  lr_actor: 0.0003
  lr_critic: 0.0003
  lr_alpha: 0.0003
  
  # 网络结构
  hidden_dim: 256
  
  # 熵调整
  auto_entropy_tuning: true      # 关闭自动调整
  alpha: 0.4                       # 固定alpha (auto_entropy_tuning=false时使用)

# ==================== PPO算法配置 ====================
ppo:
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  lr_actor: 0.0003
  lr_critic: 0.0003
  entropy_coef: 0.01
  value_coef: 0.5
  hidden_dim: 256
  ppo_epochs: 10
  max_grad_norm: 0.5
  rollout_length: 2048
  mini_batch_size: 512

# ==================== TD3算法配置 ====================
td3:
  gamma: 0.99
  tau: 0.005
  lr_actor: 0.0003
  lr_critic: 0.0003
  hidden_dim: 256
  policy_noise: 0.2
  noise_clip: 0.5
  policy_freq: 2
  exploration_noise: 0.1

# ==================== Baseline控制器配置 ====================
baseline:
  num_tactile: 19
  contact_threshold: 0.2
  twist_gain: 0.15
  closure_gain: 0.3
  release_gain: 0.1
  damping_gain: 0.05

# ==================== 训练配置 ====================
training:
  algo: sac                       # 默认算法，可被命令行参数覆盖
  # 总训练步数
  total_timesteps: 400000
  
  # 开始学习前的随机探索步数
  start_steps: 10000
  
  # 经验回放池
  buffer_size: 500000
  batch_size: 512
  
  # 更新频率
  update_every: 20                 # 每N步更新一次
  updates_per_step: 1              # 每次更新执行的梯度步数
  
  # 梯度裁剪
  grad_clip: 1.0                   # 梯度裁剪阈值
  
  # 评估
  eval_freq: 10000                 # 评估频率 (步数)
  eval_episodes: 5                 # 评估时运行的episode数
  
  # 保存
  save_freq: 50000                 # 模型保存频率 (步数)
  checkpoint_dir: "checkpoints/{algo}"
  
  # 日志
  log_dir: "logs"
  log_freq: 1000                   # 日志记录频率 (步数)
  
  # 随机种子
  seed: 42
  
  # 设备
  device: "auto"                   # "auto", "cuda", "cpu"

# ==================== 演示配置 ====================
demo:
  # 加载的模型路径
  model_path: "checkpoints/sac/best_model.pth"
  
  # 渲染帧率
  render_fps: 30
  
  # 演示episode数
  num_episodes: 10
  
  # 是否打印触觉信息
  print_tactile: true
